{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import gzip\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_binary_labels_by_digit(labels_in, digit):\n",
    "    d = np.zeros((labels_in.shape[0],1))\n",
    "\n",
    "    for i in range(labels_in.shape[0]):\n",
    "        if labels_in[i] == digit:\n",
    "            d[i] = 1\n",
    "        else:\n",
    "            d[i] = -1\n",
    "    \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-49adb0a9d187>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-49adb0a9d187>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def select_random_subset(features, labels, subset_size)\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def select_random_subset(features, labels, subset_size):\n",
    "    set_indices = np.arange(labels.shape[0])\n",
    "    subset_indices = np.random.choice(set_indices,5,replace=False)\n",
    "    \n",
    "    subset_features = np.zeros((subset_size, features.shape[1]))\n",
    "    subset_labels = np.zeros((subset_size, 1))\n",
    "    \n",
    "    for i, subset_index in enumerate(subset_indices):\n",
    "        subset_features[i] = features[subset_index]\n",
    "        subset_labels[i] = labels[subset_index]\n",
    "        \n",
    "    return subset_features, subset_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify size of images\n",
    "image_rows = 28\n",
    "image_cols = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open training set image file\n",
    "f = gzip.open('train-images-idx3-ubyte.gz','r')\n",
    "\n",
    "num_train_images = 60000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_rows * image_cols * num_train_images)\n",
    "train_data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "train_data = train_data.reshape(num_train_images, image_rows, image_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open training set label file\n",
    "\n",
    "f = gzip.open('train-labels-idx1-ubyte.gz','r')\n",
    "f.read(8)\n",
    "\n",
    "buf = f.read(num_train_images)\n",
    "train_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "train_labels = train_labels.reshape(num_train_images,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (60000, 28, 28, 1) \n",
      "\n",
      "image index 0:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [5.]\n",
      "(28, 28, 1)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# troubleshoot data import\n",
    "\n",
    "ind = 0\n",
    "\n",
    "print('training data:', train_data.shape, '\\n')\n",
    "\n",
    "# print training image\n",
    "print('image index ' + str(ind) + ':')\n",
    "image = np.asarray(train_data[ind]).squeeze()\n",
    "#plt.title(['image index', ind])\n",
    "plt.imshow(image, cmap='Greys')\n",
    "plt.show()\n",
    "# print training label\n",
    "print('label:', train_labels[ind])\n",
    "\n",
    "print(train_data[ind].shape)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open test set image file\n",
    "f = gzip.open('t10k-images-idx3-ubyte.gz','r')\n",
    "\n",
    "num_test_images = 10000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_rows * image_cols * num_test_images)\n",
    "test_data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "test_data = test_data.reshape(num_test_images, image_rows, image_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open test set label file\n",
    "\n",
    "f = gzip.open('t10k-labels-idx1-ubyte.gz','r')\n",
    "f.read(8)\n",
    "buf = f.read(num_test_images)\n",
    "test_labels = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "test_labels = test_labels.reshape(num_test_images,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: (10000, 28, 28, 1)\n",
      "image index 0:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [7.]\n"
     ]
    }
   ],
   "source": [
    "# troubleshoot test data import\n",
    "\n",
    "ind = 0\n",
    "\n",
    "print('test data:', test_data.shape)\n",
    "\n",
    "# print training image\n",
    "print('image index ' + str(ind) + ':')\n",
    "image = np.asarray(test_data[ind]).squeeze()\n",
    "#plt.title(['image index', ind])\n",
    "plt.imshow(image, cmap='Greys')\n",
    "plt.show()\n",
    "# print training label\n",
    "print('label:', test_labels[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Sqaures Classification with Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda: 0.1 - avg: 0.03717 - [0.0167, 0.0176, 0.0371, 0.0431, 0.0291, 0.0517, 0.0263, 0.0301, 0.0617, 0.0583]\n",
      "lamda: 0.285 - avg: 0.03713 - [0.0167, 0.0175, 0.0371, 0.0432, 0.0291, 0.0516, 0.0262, 0.0301, 0.0617, 0.0581]\n",
      "lamda: 0.811 - avg: 0.03717 - [0.0167, 0.0175, 0.0372, 0.0432, 0.0292, 0.0515, 0.0261, 0.0301, 0.062, 0.0582]\n",
      "lamda: 2.31 - avg: 0.03715 - [0.0168, 0.0175, 0.0371, 0.0432, 0.0292, 0.0515, 0.026, 0.03, 0.062, 0.0582]\n",
      "lamda: 6.579 - avg: 0.03715 - [0.0168, 0.0175, 0.037, 0.0431, 0.0292, 0.0514, 0.0258, 0.0299, 0.062, 0.0588]\n",
      "lamda: 18.738 - avg: 0.03714 - [0.0166, 0.0174, 0.0368, 0.043, 0.0293, 0.0516, 0.0256, 0.03, 0.062, 0.0591]\n",
      "lamda: 53.367 - avg: 0.0372 - [0.0167, 0.0171, 0.0369, 0.0429, 0.0298, 0.0521, 0.0254, 0.0299, 0.0619, 0.0593]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9039a0996dbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# train with first 50K\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0md_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_binary_labels_by_digit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_opt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mA_train\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mA_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0md_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# evaluate classifier with last 10K\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimize best regularizer\n",
    "lamdas = np.logspace(-1,4,num=12)\n",
    "digits = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# normalize array and reshape into flattened image vectors, and shuffle randomly\n",
    "A_opt = train_data.reshape(num_train_images, image_rows*image_cols)/255\n",
    "d_opt = train_labels\n",
    "\n",
    "# randomly shuffle\n",
    "A_opt = np.hstack((A_opt, d_opt))\n",
    "np.random.shuffle(A_opt)\n",
    "d_opt = A_opt[:,-1:]\n",
    "A_opt = A_opt[:,:-1]\n",
    "\n",
    "# find best lamda for all binary classifiers\n",
    "A_train = A_opt[:50000,:]\n",
    "A_eval = A_opt[50000:,:]\n",
    "avg_error_rate_by_lamda = [0] * len(lamdas)\n",
    "\n",
    "# for every lamda, get avg error rate over all digits\n",
    "for i, lamda in enumerate(lamdas):\n",
    "\n",
    "    error_rate_by_digit = [0] * len(digits)\n",
    "    \n",
    "    # get error rate for every digit\n",
    "    for digit in digits:\n",
    "        \n",
    "        # train with first 50K\n",
    "        d_train = set_binary_labels_by_digit(d_opt[:50000,:], digit)\n",
    "        w = np.linalg.inv(A_train.T@A_train+lamda*np.identity(A_train.shape[1]))@A_train.T@d_train\n",
    "        \n",
    "        # evaluate classifier with last 10K\n",
    "        d_eval = set_binary_labels_by_digit(d_opt[50000:,:], digit)\n",
    "        d_hat_eval = np.sign(A_eval@w)\n",
    "        errors = np.count_nonzero(d_eval-d_hat_eval!=0)\n",
    "        #print(digit, errors)\n",
    "        error_rate_by_digit[digit] = (errors/d_hat_eval.shape[0])\n",
    "        \n",
    "    avg_error_rate_by_lamda[i] = np.average(error_rate_by_digit)\n",
    "    print('lamda:', np.round(lamda,3), '- avg:', np.round(avg_error_rate_by_lamda[i],5), '-', error_rate_by_digit)\n",
    "\n",
    "print('\\nlamdas:\\n', np.round(lamdas,3), '\\naverage error:\\n', np.round(avg_error_rate_by_lamda,5), '\\n')\n",
    "\n",
    "#pick lamda with lowest avg error rate\n",
    "lamda = lamdas[np.argmin(avg_error_rate_by_lamda)]\n",
    "print('best lamda:', lamda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "avg training error: 0.03665\n",
      "avg test error: 0.03662\n"
     ]
    }
   ],
   "source": [
    "# train classifier with optimized regularizer\n",
    "\n",
    "A_train = train_data.reshape(num_train_images, image_rows*image_cols)/255\n",
    "A_test = test_data.reshape(num_test_images, image_rows*image_cols)/255\n",
    "\n",
    "W = np.zeros((A_train.shape[1],len(digits)))\n",
    "print(W.shape)\n",
    "\n",
    "# train and test classifier for every digit\n",
    "train_error_rate_by_digit = [0] * len(digits)\n",
    "test_error_rate_by_digit = [0] * len(digits)\n",
    "\n",
    "for digit in digits:\n",
    "\n",
    "    # train classifier with optimized lamda and training data\n",
    "    d_train = set_binary_labels_by_digit(train_labels, digit)\n",
    "    W[:,digit:digit+1] = np.linalg.inv(A_train.T@A_train+lamda*np.identity(A_train.shape[1]))@A_train.T@d_train\n",
    "    \n",
    "    # find training error\n",
    "    d_hat_train = np.sign(A_train@W[:,digit:digit+1])\n",
    "    errors = np.count_nonzero(d_train-d_hat_train!=0)\n",
    "    train_error_rate_by_digit[digit] = (errors/d_hat_train.shape[0])\n",
    "    \n",
    "    # test trained classifier with test data\n",
    "    d_test = set_binary_labels_by_digit(test_labels, digit)\n",
    "    d_hat_test = np.sign(A_test@W[:,digit:digit+1])\n",
    "    errors = np.count_nonzero(d_test-d_hat_test!=0)\n",
    "    test_error_rate_by_digit[digit] = (errors/d_hat_test.shape[0])\n",
    "    \n",
    "print('avg training error:', np.average(train_error_rate_by_digit))\n",
    "print('avg test error:', np.average(test_error_rate_by_digit))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ista_solve_hot( A, d, la_array ):\n",
    "    # ista_solve_hot: Iterative soft-thresholding for multiple values of\n",
    "    # lambda with hot start for each case - the converged value for the previous\n",
    "    # value of lambda is used as an initial condition for the current lambda.\n",
    "    # this function solves the minimization problem\n",
    "    # Minimize |Ax-d|_2^2 + lambda*|x|_1 (Lasso regression)\n",
    "    # using iterative soft-thresholding.\n",
    "    max_iter = 10**4\n",
    "    tol = 10**(-3)\n",
    "    tau = 1/np.linalg.norm(A,2)**2\n",
    "    n = A.shape[1]\n",
    "    w = np.zeros((n,1))\n",
    "    num_lam = len(la_array)\n",
    "    X = np.zeros((n, num_lam))\n",
    "    for i, each_lambda in enumerate(la_array):\n",
    "        print('lamda:',each_lambda)\n",
    "        for j in range(max_iter):\n",
    "            z = w - tau*(A.T@(A@w-d))\n",
    "            w_old = w\n",
    "            w = np.sign(z) * np.clip(np.abs(z)-tau*each_lambda/2, 0, np.inf)\n",
    "            X[:, i:i+1] = w\n",
    "            if np.linalg.norm(w - w_old) < tol:\n",
    "                break\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "lamda: 0.01\n",
      "lamda: 0.02848035868435802\n",
      "lamda: 0.08111308307896872\n",
      "lamda: 0.23101297000831592\n",
      "lamda: 0.6579332246575679\n",
      "lamda: 1.873817422860383\n",
      "lamda: 5.336699231206307\n",
      "lamda: 15.199110829529332\n",
      "lamda: 43.28761281083057\n",
      "lamda: 123.28467394420659\n",
      "lamda: 351.11917342151276\n",
      "lamda: 1000.0\n",
      "0 [0.0188 0.0188 0.0188 0.0188 0.0188 0.0188 0.0188 0.0188 0.0188 0.0188\n",
      " 0.0193 0.0215]\n",
      "lamda: 0.01\n"
     ]
    }
   ],
   "source": [
    "# optimize best regularizer\n",
    "lamdas = np.logspace(-2,3,num=12)\n",
    "digits = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# normalize array and reshape into flattened image vectors\n",
    "A_opt = train_data.reshape(num_train_images, image_rows*image_cols)/255\n",
    "d_opt = train_labels\n",
    "\n",
    "# randomly shuffle\n",
    "A_opt = np.hstack((A_opt, d_opt))\n",
    "np.random.shuffle(A_opt)\n",
    "d_opt = A_opt[:,-1:]\n",
    "A_opt = A_opt[:,:-1]\n",
    "\n",
    "# find best lamda for all binary classifiers\n",
    "A_train = A_opt[:50000,:]\n",
    "A_eval = A_opt[50000:,:]\n",
    "avg_error_rate_by_lamda = [0] * len(lamdas)\n",
    "print(A_opt.shape)\n",
    "   \n",
    "# get error rate for every digit\n",
    "error_rates = np.zeros((len(digits),len(lamdas)))\n",
    "for digit in digits:\n",
    "    print(digit)\n",
    "    # train with first 50K\n",
    "    d_train = set_binary_labels_by_digit(d_opt[:50000,:], digit)\n",
    "    W = ista_solve_hot(A_train,d_train,lamdas)\n",
    "\n",
    "    # evaluate classifier with last 10K\n",
    "    d_eval = set_binary_labels_by_digit(d_opt[50000:,:], digit)\n",
    "    d_hat_eval = np.sign(A_eval@W)\n",
    "    errors = np.count_nonzero(d_eval-d_hat_eval!=0,axis=0)\n",
    "    error_rates[digit] = (errors/d_hat_eval.shape[0])\n",
    "    print(digit, error_rates[digit])\n",
    "\n",
    "print(error_rates)\n",
    "avg_error_rate_by_lamda = np.average(error_rates, axis=0)\n",
    "print('lamdas:\\n', lamdas, '\\n', avg_error_rate_by_lamda, '\\n')\n",
    "\n",
    "#pick lamda with lowest avg error rate\n",
    "lamda = np.array([lamdas[np.argmin(avg_error_rate_by_lamda)]])\n",
    "print('best lamda:', lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lamda: [15.19911083]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pick lamda with lowest avg error rate\n",
    "lamda = np.array([lamdas[np.argmin(avg_error_rate_by_lamda)]])\n",
    "print('best lamda:', lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "training errors: [0.0187, 0.017933333333333332, 0.03961666666666667, 0.04688333333333333, 0.03626666666666667, 0.0615, 0.023683333333333334, 0.0284, 0.07098333333333333, 0.06953333333333334]\n",
      "test errors: [0.0156, 0.0162, 0.0397, 0.0452, 0.0362, 0.0589, 0.0249, 0.0283, 0.0752, 0.0659]\n",
      "avg training error: 0.041350000000000005\n",
      "avg test error: 0.04061\n"
     ]
    }
   ],
   "source": [
    "# train classifier with optimized regularizer\n",
    "\n",
    "A_train = train_data.reshape(num_train_images, image_rows*image_cols)/255\n",
    "A_test = test_data.reshape(num_test_images, image_rows*image_cols)/255\n",
    "\n",
    "W = np.zeros((A_train.shape[1],len(digits)))\n",
    "print(W.shape)\n",
    "\n",
    "# train and test classifier for every digit\n",
    "train_error_rate_by_digit = [0] * len(digits)\n",
    "test_error_rate_by_digit = [0] * len(digits)\n",
    "\n",
    "for digit in digits:\n",
    "    #print(digit)\n",
    "    # train classifier with optimized lamda and training data\n",
    "    d_train = set_binary_labels_by_digit(train_labels, digit)\n",
    "    W[:,digit:digit+1] = ista_solve_hot(A_train,d_train,lamda)\n",
    "    \n",
    "    # find training error\n",
    "    d_hat_train = np.sign(A_train@W[:,digit:digit+1])\n",
    "    errors = np.count_nonzero(d_train-d_hat_train!=0)\n",
    "    train_error_rate_by_digit[digit] = (errors/d_hat_train.shape[0])\n",
    "    \n",
    "    # test trained classifier with test data\n",
    "    d_test = set_binary_labels_by_digit(test_labels, digit)\n",
    "    d_hat_test = np.sign(A_test@W[:,digit:digit+1])\n",
    "    errors = np.count_nonzero(d_test-d_hat_test!=0)\n",
    "    test_error_rate_by_digit[digit] = (errors/d_hat_test.shape[0])\n",
    "\n",
    "print('training errors:', train_error_rate_by_digit)\n",
    "print('test errors:', test_error_rate_by_digit)\n",
    "\n",
    "print('avg training error:', np.average(train_error_rate_by_digit))\n",
    "print('avg test error:', np.average(test_error_rate_by_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 10)\n",
      "avg training error: 0.04383\n",
      "avg test error: 0.04546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "A_train = train_data.reshape(num_train_images, image_rows*image_cols)/255\n",
    "A_test = test_data.reshape(num_test_images, image_rows*image_cols)/255\n",
    "\n",
    "n_train = np.size(A_train[:,0:1])\n",
    "n_test = np.size(A_test[:,0:1])\n",
    "\n",
    "A_train_1 = np.hstack((A_train, np.ones((n_train,1)) ))\n",
    "A_test_1 = np.hstack((A_test, np.ones((n_test,1)) ))\n",
    "\n",
    "\n",
    "\n",
    "# train and test classifier for every digit\n",
    "train_error_rate_by_digit = [0] * len(digits)\n",
    "test_error_rate_by_digit = [0] * len(digits)\n",
    "digits = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "W = np.zeros((A_train_1.shape[1],len(digits)))\n",
    "print(W.shape)\n",
    "\n",
    "for digit in digits:\n",
    "\n",
    "   # Train classifier using linear SVM from SK Learn library\n",
    "    clf = LinearSVC(random_state=0, dual=False)\n",
    "    d_train = set_binary_labels_by_digit(train_labels, digit)\n",
    "    clf.fit(A_train_1, np.squeeze(d_train))\n",
    "    W[:,digit:digit+1] = clf.coef_.transpose()\n",
    "    #print('done training', digit)\n",
    "    \n",
    "    # find training error\n",
    "    d_hat_train = np.sign(A_train_1@W[:,digit:digit+1])\n",
    "    errors = np.count_nonzero(d_train-d_hat_train!=0)\n",
    "    train_error_rate_by_digit[digit] = (errors/d_hat_train.shape[0])\n",
    "    #print(digit, 'training error:', train_error_rate_by_digit[digit])\n",
    "\n",
    "    \n",
    "    # test trained classifier with test data\n",
    "    d_test = set_binary_labels_by_digit(test_labels, digit)\n",
    "    d_hat_test = np.sign(A_test_1@W[:,digit:digit+1])\n",
    "    errors = np.count_nonzero(d_test-d_hat_test!=0)\n",
    "    test_error_rate_by_digit[digit] = (errors/d_hat_test.shape[0])\n",
    "    #print(digit, 'test error:', est_error_rate_by_digit[digit])\n",
    "\n",
    "    \n",
    "print('avg training error:', np.average(train_error_rate_by_digit))\n",
    "print('avg test error:', np.average(test_error_rate_by_digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vec = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat_outlier, y_eval))]\n",
    "plt.scatter(x_eval[:,0],x_eval[:,1], color=['c' if i==0 else 'r' for i in error_vec])\n",
    "plt.title('errors')\n",
    "plt.show()\n",
    "\n",
    "print('Errors: '+ str(sum(error_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(X, K, maxIters = 20):\n",
    "\n",
    "    centroids = X[np.random.choice(len(X), K)]\n",
    "    for i in range(maxIters):\n",
    "        # Cluster Assignment step\n",
    "        C = np.array([np.argmin([(x_i-y_k)@(x_i-y_k) for y_k in centroids]) for x_i in X])\n",
    "        # Update centroids step \n",
    "        centroids = []\n",
    "        for k in range(K):\n",
    "            if (C == k).any():\n",
    "                centroids.append( X[C == k].mean(axis = 0) )\n",
    "            else: # if there are no data points assigned to this certain centroid\n",
    "                centroids.append( X[np.random.choice(len(X))] )\n",
    "    return np.array(centroids) , C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train = train_data.reshape(num_train_images, image_rows*image_cols)/255\n",
    "\n",
    "centroids, C = kMeans(A_train, K = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('centroid assigned = ',C, sep=\"\\n\", end='\\n\\n')\n",
    "print('centroids =', centroids.T.round(3), sep=\"\\n\", end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
